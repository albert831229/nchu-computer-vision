{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMO3Mx7a85HfORd2WTfX5FB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Replicating LeNet and AlexNet in Tensorflow2.0 using Keras**\n","\n","---\n","\n","In this lesson, we use **Keras with a TensorFlow 2.0** Backend to to replicate both **LeNet and AlexNet** in Keras and train it to **recognize handwritten digits in the MNIST dataset and the 10 images classes of CIFAR10**\n","1. Replicate the LeNet CNN Architecture\n","2. Replicate the AlexNet CNN Architecture"],"metadata":{"id":"DzvFzWUK_JS3"}},{"cell_type":"markdown","source":["## **Let's construct LeNet in Keras!**\n","\n","![](https://www.researchgate.net/profile/Sheraz_Khan8/publication/321586653/figure/fig4/AS:568546847014912@1512563539828/The-LeNet-5-Architecture-a-convolutional-neural-network.png)\n","## **LeNet Architecture**\n","S.No | Layers | Output Shape (Height, Width, Channels)\n","--- | --- | ---\n","1 | Input Layer | 32 x 32 x 1\n","2 | Conv2d [6 Filters of size = 5x5, stride = 1, padding = 0 ] | 28 x 28 x 6\n","3 | Average Pooling [stride = 2, padding = 0] | 14 x 14 x 6\n","4 | Conv2d [16 Filters of size = 5x5, stride = 1, padding = 0 ] | 10 x 10 x 16\n","5 | Average Pooling [stride = 2, padding = 0] | 5 x 5 x 16\n","6 | Conv2d [120 Filters of size = 5x5, stride = 1, padding = 0 ] | 1 x 1 x 120\n","7 | Linear1 Layer | 120\n","8 | Linear2 Layer | 84\n","9 | Final Linear Layer | 10\n","\n","\n","### **Loading and preprocessing our Data**"],"metadata":{"id":"7CAsC-FW_QSm"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adadelta\n","\n","# loads the MNIST dataset\n","(x_train, y_train), (x_test, y_test)  = mnist.load_data()\n","\n","# Lets store the number of rows and columns\n","img_rows = x_train[0].shape[0]\n","img_cols = x_train[1].shape[0]\n","\n","# Getting our date in the right 'shape' needed for Keras\n","# We need to add a 4th dimenion to our date thereby changing our\n","# Our original image shape of (60000,28,28) to (60000,28,28,1)\n","x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","\n","# store the shape of a single image\n","input_shape = (img_rows, img_cols, 1)\n","\n","# change our image type to float32 data type\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","# Normalize our data by changing the range from (0 to 255) to (0 to 1)\n","x_train /= 255\n","x_test /= 255\n","\n","# Now we one hot encode outputs\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","num_classes = y_test.shape[1]\n","num_pixels = x_train.shape[1] * x_train.shape[2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"errH3Mu5_KGL","executionInfo":{"status":"ok","timestamp":1697520032365,"user_tz":-480,"elapsed":5598,"user":{"displayName":"楊景明","userId":"02385702773581765739"}},"outputId":"714b9e40-d5fd-4dfc-d67c-70def4183d1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","source":["### **Now let's create our layers to replicate LeNet**"],"metadata":{"id":"e8UBgdDT_eBZ"}},{"cell_type":"code","source":["# create model\n","model = Sequential()\n","\n","# 2 sets of CRP (Convolution, RELU, Pooling)\n","model.add(Conv2D(6, (5, 5),\n","                 padding = \"same\", # padding is set to 0 in the original paper, to set padding at 0, use \"valid\"\n","                 input_shape = input_shape))\n","model.add(Activation(\"relu\"))\n","model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","\n","model.add(Conv2D(16, (5, 5),\n","                 padding = \"same\"))\n","model.add(Activation(\"relu\"))\n","model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","\n","model.add(Conv2D(120, (5, 5),\n","                 padding = \"same\"))\n","model.add(Activation(\"relu\"))\n","model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n","\n","# Fully connected layers (w/ RELU)\n","model.add(Flatten())\n","model.add(Dense(120))\n","model.add(Activation(\"relu\"))\n","\n","model.add(Dense(84))\n","model.add(Activation(\"relu\"))\n","# Softmax (for classification)\n","model.add(Dense(num_classes))\n","model.add(Activation(\"softmax\"))\n","\n","model.compile(loss = 'categorical_crossentropy',\n","              optimizer = Adadelta(),\n","              metrics = ['accuracy'])\n","\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J00cFt6Z_bpk","executionInfo":{"status":"ok","timestamp":1697520035603,"user_tz":-480,"elapsed":3241,"user":{"displayName":"楊景明","userId":"02385702773581765739"}},"outputId":"1e99654f-d5a2-4510-e7b4-42cdca3190fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 28, 28, 6)         156       \n","                                                                 \n"," activation (Activation)     (None, 28, 28, 6)         0         \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 14, 14, 6)         0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 14, 14, 16)        2416      \n","                                                                 \n"," activation_1 (Activation)   (None, 14, 14, 16)        0         \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 7, 7, 16)          0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 7, 7, 120)         48120     \n","                                                                 \n"," activation_2 (Activation)   (None, 7, 7, 120)         0         \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 3, 3, 120)         0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 1080)              0         \n","                                                                 \n"," dense (Dense)               (None, 120)               129720    \n","                                                                 \n"," activation_3 (Activation)   (None, 120)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 84)                10164     \n","                                                                 \n"," activation_4 (Activation)   (None, 84)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                850       \n","                                                                 \n"," activation_5 (Activation)   (None, 10)                0         \n","                                                                 \n","=================================================================\n","Total params: 191426 (747.76 KB)\n","Trainable params: 191426 (747.76 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"markdown","source":["### **Now let us train LeNet on our MNIST Dataset**"],"metadata":{"id":"gVv2kpzBAAz1"}},{"cell_type":"code","source":["# Training Parameters\n","batch_size = 128\n","epochs = 50\n","\n","history = model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_data=(x_test, y_test),\n","          shuffle=True)\n","\n","model.save(\"mnist_LeNet.h5\")\n","\n","# Evaluate the performance of our trained model\n","scores = model.evaluate(x_test, y_test, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hYvY5y_G_oKd","executionInfo":{"status":"ok","timestamp":1697435114990,"user_tz":-480,"elapsed":204967,"user":{"displayName":"楊景明","userId":"02385702773581765739"}},"outputId":"5def7a72-10a2-483d-bfed-54c1b054dea5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","469/469 [==============================] - 16s 7ms/step - loss: 2.3027 - accuracy: 0.1167 - val_loss: 2.2963 - val_accuracy: 0.1347\n","Epoch 2/50\n","469/469 [==============================] - 3s 6ms/step - loss: 2.2902 - accuracy: 0.1597 - val_loss: 2.2835 - val_accuracy: 0.2096\n","Epoch 3/50\n","469/469 [==============================] - 3s 6ms/step - loss: 2.2777 - accuracy: 0.2660 - val_loss: 2.2704 - val_accuracy: 0.3153\n","Epoch 4/50\n","469/469 [==============================] - 3s 7ms/step - loss: 2.2646 - accuracy: 0.3360 - val_loss: 2.2564 - val_accuracy: 0.3668\n","Epoch 5/50\n","469/469 [==============================] - 3s 7ms/step - loss: 2.2496 - accuracy: 0.3776 - val_loss: 2.2394 - val_accuracy: 0.4139\n","Epoch 6/50\n","469/469 [==============================] - 3s 6ms/step - loss: 2.2308 - accuracy: 0.4229 - val_loss: 2.2174 - val_accuracy: 0.4498\n","Epoch 7/50\n","469/469 [==============================] - 3s 6ms/step - loss: 2.2059 - accuracy: 0.4622 - val_loss: 2.1884 - val_accuracy: 0.4888\n","Epoch 8/50\n","469/469 [==============================] - 3s 6ms/step - loss: 2.1734 - accuracy: 0.5029 - val_loss: 2.1501 - val_accuracy: 0.5344\n","Epoch 9/50\n","469/469 [==============================] - 4s 8ms/step - loss: 2.1300 - accuracy: 0.5534 - val_loss: 2.0987 - val_accuracy: 0.5817\n","Epoch 10/50\n","469/469 [==============================] - 3s 6ms/step - loss: 2.0716 - accuracy: 0.5959 - val_loss: 2.0293 - val_accuracy: 0.6243\n","Epoch 11/50\n","469/469 [==============================] - 3s 6ms/step - loss: 1.9934 - accuracy: 0.6373 - val_loss: 1.9372 - val_accuracy: 0.6590\n","Epoch 12/50\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8908 - accuracy: 0.6748 - val_loss: 1.8181 - val_accuracy: 0.7092\n","Epoch 13/50\n","469/469 [==============================] - 3s 7ms/step - loss: 1.7613 - accuracy: 0.7200 - val_loss: 1.6717 - val_accuracy: 0.7548\n","Epoch 14/50\n","469/469 [==============================] - 3s 6ms/step - loss: 1.6071 - accuracy: 0.7525 - val_loss: 1.5028 - val_accuracy: 0.7800\n","Epoch 15/50\n","469/469 [==============================] - 3s 6ms/step - loss: 1.4371 - accuracy: 0.7716 - val_loss: 1.3267 - val_accuracy: 0.7936\n","Epoch 16/50\n","469/469 [==============================] - 3s 6ms/step - loss: 1.2689 - accuracy: 0.7831 - val_loss: 1.1609 - val_accuracy: 0.8013\n","Epoch 17/50\n","469/469 [==============================] - 3s 6ms/step - loss: 1.1156 - accuracy: 0.7911 - val_loss: 1.0165 - val_accuracy: 0.8107\n","Epoch 18/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.9867 - accuracy: 0.8008 - val_loss: 0.9005 - val_accuracy: 0.8194\n","Epoch 19/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.8838 - accuracy: 0.8095 - val_loss: 0.8091 - val_accuracy: 0.8277\n","Epoch 20/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.8026 - accuracy: 0.8177 - val_loss: 0.7378 - val_accuracy: 0.8324\n","Epoch 21/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.7384 - accuracy: 0.8248 - val_loss: 0.6812 - val_accuracy: 0.8398\n","Epoch 22/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.6866 - accuracy: 0.8314 - val_loss: 0.6351 - val_accuracy: 0.8454\n","Epoch 23/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6439 - accuracy: 0.8385 - val_loss: 0.5970 - val_accuracy: 0.8520\n","Epoch 24/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6083 - accuracy: 0.8441 - val_loss: 0.5650 - val_accuracy: 0.8566\n","Epoch 25/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5779 - accuracy: 0.8495 - val_loss: 0.5374 - val_accuracy: 0.8600\n","Epoch 26/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5516 - accuracy: 0.8551 - val_loss: 0.5137 - val_accuracy: 0.8663\n","Epoch 27/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5283 - accuracy: 0.8592 - val_loss: 0.4928 - val_accuracy: 0.8717\n","Epoch 28/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5079 - accuracy: 0.8638 - val_loss: 0.4741 - val_accuracy: 0.8760\n","Epoch 29/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4898 - accuracy: 0.8678 - val_loss: 0.4576 - val_accuracy: 0.8796\n","Epoch 30/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4734 - accuracy: 0.8720 - val_loss: 0.4429 - val_accuracy: 0.8837\n","Epoch 31/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.4587 - accuracy: 0.8755 - val_loss: 0.4290 - val_accuracy: 0.8866\n","Epoch 32/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4453 - accuracy: 0.8782 - val_loss: 0.4169 - val_accuracy: 0.8903\n","Epoch 33/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4330 - accuracy: 0.8812 - val_loss: 0.4053 - val_accuracy: 0.8927\n","Epoch 34/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4219 - accuracy: 0.8838 - val_loss: 0.3951 - val_accuracy: 0.8947\n","Epoch 35/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.4114 - accuracy: 0.8862 - val_loss: 0.3855 - val_accuracy: 0.8970\n","Epoch 36/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4017 - accuracy: 0.8881 - val_loss: 0.3763 - val_accuracy: 0.8996\n","Epoch 37/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3927 - accuracy: 0.8904 - val_loss: 0.3679 - val_accuracy: 0.8997\n","Epoch 38/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3843 - accuracy: 0.8922 - val_loss: 0.3600 - val_accuracy: 0.9026\n","Epoch 39/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3763 - accuracy: 0.8941 - val_loss: 0.3532 - val_accuracy: 0.9055\n","Epoch 40/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3690 - accuracy: 0.8963 - val_loss: 0.3455 - val_accuracy: 0.9067\n","Epoch 41/50\n","469/469 [==============================] - 3s 5ms/step - loss: 0.3619 - accuracy: 0.8976 - val_loss: 0.3396 - val_accuracy: 0.9078\n","Epoch 42/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3553 - accuracy: 0.8999 - val_loss: 0.3332 - val_accuracy: 0.9089\n","Epoch 43/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3491 - accuracy: 0.9013 - val_loss: 0.3271 - val_accuracy: 0.9105\n","Epoch 44/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3431 - accuracy: 0.9026 - val_loss: 0.3221 - val_accuracy: 0.9107\n","Epoch 45/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3374 - accuracy: 0.9041 - val_loss: 0.3169 - val_accuracy: 0.9118\n","Epoch 46/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3320 - accuracy: 0.9050 - val_loss: 0.3115 - val_accuracy: 0.9137\n","Epoch 47/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3267 - accuracy: 0.9062 - val_loss: 0.3066 - val_accuracy: 0.9145\n","Epoch 48/50\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3217 - accuracy: 0.9075 - val_loss: 0.3023 - val_accuracy: 0.9162\n","Epoch 49/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3168 - accuracy: 0.9088 - val_loss: 0.2973 - val_accuracy: 0.9179\n","Epoch 50/50\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3122 - accuracy: 0.9098 - val_loss: 0.2933 - val_accuracy: 0.9195\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 0.2933 - accuracy: 0.9195\n","Test loss: 0.29328733682632446\n","Test accuracy: 0.9194999933242798\n"]}]},{"cell_type":"markdown","source":["## **Now let's replicate AlexNET and train in on the CIFAR10 Dataset**\n","\n","AlexNet was the 2012 ImageNet winner achieved a top-5 error of 15.3%, more than 10.8 percentage points lower than that of the runner up!\n","\n","![](https://paperswithcode.com/media/methods/Screen_Shot_2020-06-22_at_6.35.45_PM.png)\n","\n","![](https://production-media.paperswithcode.com/datasets/CIFAR-10-0000000431-b71f61c0_U5n3Glr.jpg)"],"metadata":{"id":"jnVURVZEAYg7"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adadelta\n","from tensorflow.keras.utils import to_categorical\n","\n","# Loads the CIFAR dataset\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","# Display our data shape/dimensions\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Now we one hot encode outputs\n","num_classes = 10\n","y_train = to_categorical(y_train, num_classes)\n","y_test = to_categorical(y_test, num_classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dco8Gns0AC3N","executionInfo":{"status":"ok","timestamp":1697520915763,"user_tz":-480,"elapsed":8150,"user":{"displayName":"楊景明","userId":"02385702773581765739"}},"outputId":"2fcb676f-0809-4760-f457-0db5c1d4971c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 5s 0us/step\n","x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"]}]},{"cell_type":"code","source":["l2_reg = 0.001\n","\n","# Initialize model\n","model = Sequential()\n","\n","# 1st Conv Layer\n","model.add(Conv2D(96, (11, 11), input_shape=x_train.shape[1:],\n","    padding='same', kernel_regularizer=l2(l2_reg)))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 2nd Conv Layer\n","model.add(Conv2D(256, (5, 5), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 3rd Conv Layer\n","model.add(ZeroPadding2D((1,2)(3,4)))\n","model.add(Conv2D(512, (3, 3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 4th Conv Layer\n","model.add(ZeroPadding2D((1, 1)))\n","model.add(Conv2D(1024, (3, 3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","\n","# 5th Conv Layer\n","model.add(ZeroPadding2D((1, 1)))\n","model.add(Conv2D(1024, (3, 3), padding='same'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 1st FC Layer\n","model.add(Flatten())\n","model.add(Dense(3072))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","# 2nd FC Layer\n","model.add(Dense(4096))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","# 3rd FC Layer\n","model.add(Dense(num_classes))\n","model.add(BatchNormalization())\n","model.add(Activation('softmax'))\n","\n","print(model.summary())\n","\n","model.compile(loss = 'categorical_crossentropy',\n","              optimizer = Adadelta(),\n","              metrics = ['accuracy'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wr_Mzs9lAgMx","executionInfo":{"status":"ok","timestamp":1697521197535,"user_tz":-480,"elapsed":544,"user":{"displayName":"楊景明","userId":"02385702773581765739"}},"outputId":"7fa8d018-ce68-422f-ddef-b9d1a793fc09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_18 (Conv2D)          (None, 32, 32, 96)        34944     \n","                                                                 \n"," batch_normalization_24 (Ba  (None, 32, 32, 96)        384       \n"," tchNormalization)                                               \n","                                                                 \n"," activation_30 (Activation)  (None, 32, 32, 96)        0         \n","                                                                 \n"," max_pooling2d_15 (MaxPooli  (None, 16, 16, 96)        0         \n"," ng2D)                                                           \n","                                                                 \n"," conv2d_19 (Conv2D)          (None, 16, 16, 256)       614656    \n","                                                                 \n"," batch_normalization_25 (Ba  (None, 16, 16, 256)       1024      \n"," tchNormalization)                                               \n","                                                                 \n"," activation_31 (Activation)  (None, 16, 16, 256)       0         \n","                                                                 \n"," max_pooling2d_16 (MaxPooli  (None, 8, 8, 256)         0         \n"," ng2D)                                                           \n","                                                                 \n"," zero_padding2d_6 (ZeroPadd  (None, 10, 10, 256)       0         \n"," ing2D)                                                          \n","                                                                 \n"," conv2d_20 (Conv2D)          (None, 10, 10, 512)       1180160   \n","                                                                 \n"," batch_normalization_26 (Ba  (None, 10, 10, 512)       2048      \n"," tchNormalization)                                               \n","                                                                 \n"," activation_32 (Activation)  (None, 10, 10, 512)       0         \n","                                                                 \n"," max_pooling2d_17 (MaxPooli  (None, 5, 5, 512)         0         \n"," ng2D)                                                           \n","                                                                 \n"," zero_padding2d_7 (ZeroPadd  (None, 7, 7, 512)         0         \n"," ing2D)                                                          \n","                                                                 \n"," conv2d_21 (Conv2D)          (None, 7, 7, 1024)        4719616   \n","                                                                 \n"," batch_normalization_27 (Ba  (None, 7, 7, 1024)        4096      \n"," tchNormalization)                                               \n","                                                                 \n"," activation_33 (Activation)  (None, 7, 7, 1024)        0         \n","                                                                 \n"," zero_padding2d_8 (ZeroPadd  (None, 9, 9, 1024)        0         \n"," ing2D)                                                          \n","                                                                 \n"," conv2d_22 (Conv2D)          (None, 9, 9, 1024)        9438208   \n","                                                                 \n"," batch_normalization_28 (Ba  (None, 9, 9, 1024)        4096      \n"," tchNormalization)                                               \n","                                                                 \n"," activation_34 (Activation)  (None, 9, 9, 1024)        0         \n","                                                                 \n"," max_pooling2d_18 (MaxPooli  (None, 4, 4, 1024)        0         \n"," ng2D)                                                           \n","                                                                 \n"," flatten_4 (Flatten)         (None, 16384)             0         \n","                                                                 \n"," dense_12 (Dense)            (None, 3072)              50334720  \n","                                                                 \n"," batch_normalization_29 (Ba  (None, 3072)              12288     \n"," tchNormalization)                                               \n","                                                                 \n"," activation_35 (Activation)  (None, 3072)              0         \n","                                                                 \n"," dropout_6 (Dropout)         (None, 3072)              0         \n","                                                                 \n"," dense_13 (Dense)            (None, 4096)              12587008  \n","                                                                 \n"," batch_normalization_30 (Ba  (None, 4096)              16384     \n"," tchNormalization)                                               \n","                                                                 \n"," activation_36 (Activation)  (None, 4096)              0         \n","                                                                 \n"," dropout_7 (Dropout)         (None, 4096)              0         \n","                                                                 \n"," dense_14 (Dense)            (None, 10)                40970     \n","                                                                 \n"," batch_normalization_31 (Ba  (None, 10)                40        \n"," tchNormalization)                                               \n","                                                                 \n"," activation_37 (Activation)  (None, 10)                0         \n","                                                                 \n","=================================================================\n","Total params: 78990642 (301.33 MB)\n","Trainable params: 78970462 (301.25 MB)\n","Non-trainable params: 20180 (78.83 KB)\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["# Training Parameters\n","batch_size = 64\n","epochs = 25\n","\n","history = model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_data=(x_test, y_test),\n","          shuffle=True)\n","\n","model.save(\"CIFAR10_AlexNet_10_Epoch.h5\")\n","\n","# Evaluate the performance of our trained model\n","scores = model.evaluate(x_test, y_test, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F-ajGuEWBNpE","executionInfo":{"status":"ok","timestamp":1697437379097,"user_tz":-480,"elapsed":2204465,"user":{"displayName":"楊景明","userId":"02385702773581765739"}},"outputId":"29e2220e-89a6-4ea6-d1a3-f8cb18899187"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","782/782 [==============================] - 97s 112ms/step - loss: 2.1335 - accuracy: 0.2457 - val_loss: 1.7633 - val_accuracy: 0.3905\n","Epoch 2/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.8479 - accuracy: 0.3399 - val_loss: 1.6670 - val_accuracy: 0.4297\n","Epoch 3/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.7451 - accuracy: 0.3867 - val_loss: 1.6035 - val_accuracy: 0.4571\n","Epoch 4/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.6836 - accuracy: 0.4130 - val_loss: 1.5598 - val_accuracy: 0.4770\n","Epoch 5/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.6334 - accuracy: 0.4366 - val_loss: 1.5260 - val_accuracy: 0.4883\n","Epoch 6/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.5943 - accuracy: 0.4518 - val_loss: 1.4972 - val_accuracy: 0.4980\n","Epoch 7/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.5623 - accuracy: 0.4699 - val_loss: 1.4698 - val_accuracy: 0.5126\n","Epoch 8/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.5355 - accuracy: 0.4812 - val_loss: 1.4502 - val_accuracy: 0.5197\n","Epoch 9/25\n","782/782 [==============================] - 85s 108ms/step - loss: 1.5072 - accuracy: 0.4949 - val_loss: 1.4308 - val_accuracy: 0.5291\n","Epoch 10/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.4854 - accuracy: 0.5068 - val_loss: 1.4114 - val_accuracy: 0.5384\n","Epoch 11/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.4633 - accuracy: 0.5160 - val_loss: 1.3967 - val_accuracy: 0.5433\n","Epoch 12/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.4435 - accuracy: 0.5267 - val_loss: 1.3841 - val_accuracy: 0.5514\n","Epoch 13/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.4262 - accuracy: 0.5349 - val_loss: 1.3722 - val_accuracy: 0.5592\n","Epoch 14/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.4073 - accuracy: 0.5460 - val_loss: 1.3620 - val_accuracy: 0.5645\n","Epoch 15/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.3917 - accuracy: 0.5547 - val_loss: 1.3475 - val_accuracy: 0.5697\n","Epoch 16/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.3735 - accuracy: 0.5617 - val_loss: 1.3360 - val_accuracy: 0.5753\n","Epoch 17/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.3564 - accuracy: 0.5711 - val_loss: 1.3285 - val_accuracy: 0.5776\n","Epoch 18/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.3446 - accuracy: 0.5745 - val_loss: 1.3179 - val_accuracy: 0.5867\n","Epoch 19/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.3317 - accuracy: 0.5808 - val_loss: 1.3108 - val_accuracy: 0.5907\n","Epoch 20/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.3132 - accuracy: 0.5956 - val_loss: 1.3008 - val_accuracy: 0.5954\n","Epoch 21/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.3016 - accuracy: 0.5992 - val_loss: 1.2941 - val_accuracy: 0.5997\n","Epoch 22/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.2895 - accuracy: 0.6042 - val_loss: 1.2888 - val_accuracy: 0.6016\n","Epoch 23/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.2709 - accuracy: 0.6165 - val_loss: 1.2797 - val_accuracy: 0.6060\n","Epoch 24/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.2584 - accuracy: 0.6204 - val_loss: 1.2720 - val_accuracy: 0.6073\n","Epoch 25/25\n","782/782 [==============================] - 85s 109ms/step - loss: 1.2500 - accuracy: 0.6238 - val_loss: 1.2652 - val_accuracy: 0.6125\n","313/313 [==============================] - 7s 21ms/step - loss: 1.2652 - accuracy: 0.6125\n","Test loss: 1.2652033567428589\n","Test accuracy: 0.612500011920929\n"]}]},{"cell_type":"markdown","source":["## **Current Top Performers in CIFAR10**\n","https://paperswithcode.com/sota/image-classification-on-cifar-10"],"metadata":{"id":"G_OG-fNRB9We"}},{"cell_type":"code","source":[],"metadata":{"id":"4fjXfZQPBUJZ"},"execution_count":null,"outputs":[]}]}